{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of Breast Tumor Malignancy with Deep Neural Network\n",
    "\n",
    "I will make a computational model for breast tumor malignancy prediction with a deep neural network.\n",
    "\n",
    "I downloaded \"Breast Cancer Wisconsin (Diagnostic) Data Set\" from https://www.kaggle.com/uciml/breast-cancer-wisconsin-data#data.csv.\n",
    "\n",
    "I downloaded the dataset on 25 July 2018.\n",
    "\n",
    "The size of dataset is 569 (# of breast tumor tissues) x 30 (# of features),\n",
    "\n",
    "Here, I will first preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 32)\n"
     ]
    }
   ],
   "source": [
    "# open data\n",
    "sInFile = open('./data.csv', 'r')\n",
    "\n",
    "# store features in features.txt\n",
    "sFeatures = sInFile.readline().replace('\"id\",\"diagnosis\",', '')\n",
    "sOutFile = open('./features.txt', 'w')\n",
    "sOutFile.write(sFeatures)\n",
    "sOutFile.close()\n",
    "\n",
    "# mark \"M\" (malignant) as (1, 0) and \"B\" (benign) as (0, 1)\n",
    "sOutFile2 = open('./data2.csv', 'w')\n",
    "\n",
    "for sReadLine in sInFile.readlines():\n",
    "\n",
    "    sOutFile2.write(sReadLine.replace('M', '1,0').replace('B', '0,1'))\n",
    "\n",
    "sInFile.close()\n",
    "sOutFile2.close()\n",
    "    \n",
    "# load data\n",
    "import numpy as np\n",
    "\n",
    "data = np.loadtxt('./data2.csv', usecols = range(1, 33), delimiter = ',')\n",
    "print(data.shape) # it should be (569, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will split the data into training dataset (60%), validation dataset (20%), and test dataset (20%).\n",
    "\n",
    "* Whole dataset file: Data.npy\n",
    "* Training dataset file: Training.npy\n",
    "* Validation dataset file: Validation.npy\n",
    "* Test dataset file: Test.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341, 32)\n",
      "(114, 32)\n",
      "(114, 32)\n"
     ]
    }
   ],
   "source": [
    "# save whole dataset\n",
    "np.save('./Data', data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training dataset (60%), validation dataset (20%), and test dataset (20%)\n",
    "data_train, data_else = train_test_split(data, test_size = 0.4, random_state = 7)\n",
    "data_valid, data_test = train_test_split(data_else, test_size = 0.5, random_state = 7)\n",
    "\n",
    "print(data_train.shape) # it should be (341, 32)\n",
    "print(data_test.shape) # it should be (114, 32)\n",
    "print(data_valid.shape) # it should be (114, 32)\n",
    "\n",
    "# save training, validation, and test datasets\n",
    "np.save('./Training', data_train)\n",
    "np.save('./Validation', data_valid)\n",
    "np.save('./Test', data_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
